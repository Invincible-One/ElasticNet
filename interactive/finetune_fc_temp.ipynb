{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetune the saved models to see whether they forgot things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "from models import get_model, model_config\n",
    "from data import data_config\n",
    "from data.datasets import TwilightDuo\n",
    "from main import get_device\n",
    "\n",
    "class ProtendArgs:\n",
    "    model = \"FullyConnectedNetwork\"\n",
    "    #model = \"VGG_like\"\n",
    "    dataset = \"TwilightDuo\"\n",
    "    model_config = [2048, 512]\n",
    "    #model_config = [32, 'M', 64, 'M', 128, 'M', 256, 'M', 512, 'M', 1024, 'M', 1024, 'M', 1024]\n",
    "\n",
    "\n",
    "def load_model(args, fname):\n",
    "    base_folder = \"/scratch/ym2380/saved_models\"\n",
    "    fname = f\"{fname}.pth\"\n",
    "    fpath = os.path.join(base_folder, args.model, args.dataset, fname)\n",
    "    \n",
    "    model = get_model(args)\n",
    "    model.load_state_dict(torch.load(fpath))\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    return model\n",
    "\n",
    "def run_epoch(\n",
    "    dataloader,\n",
    "    model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    train,\n",
    "    device,\n",
    "    ):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        network.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = len(dataloader.dataset)\n",
    "    \n",
    "    with torch.set_grad_enabled(train):\n",
    "        for batch_idx, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            if model_config[args.model][\"input_type\"] == \"flattened\":\n",
    "                X = X.view(X.size(0), -1)\n",
    "            \n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(X)\n",
    "            loss_v = loss_fn(outputs, y)\n",
    "            total_loss += loss_v.item()\n",
    "            \n",
    "            if train:\n",
    "                loss_v.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions =  (predicted == y).sum().item()\n",
    "            correct += correct_predictions\n",
    "    \n",
    "    return correct / total, total_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add fname\n",
    "fname = \"10180408_8\"\n",
    "info = {\n",
    "    \"l1_strength\": -0.001,\n",
    "    \"l2_strength\": 0.0,\n",
    "    \"lr\": 0.01,\n",
    "}\n",
    "info[\"file_name\"] = fname\n",
    "\n",
    "args = ProtendArgs()\n",
    "device = get_device()\n",
    "\n",
    "\n",
    "train_data = TwilightDuo(n_samples=500, bias=0, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=25, num_workers=1, pin_memory=True)\n",
    "val_data = TwilightDuo(n_samples=1000, bias=0, transform=transforms.ToTensor())\n",
    "val_loader = DataLoader(val_data, shuffle=False, batch_size=100, num_workers=1, pin_memory=True)\n",
    "\n",
    "network = load_model(args, fname=fname).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#try different lrs\n",
    "optimizer = optim.Adam(network.classifier.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************\n",
      "   Arguments & Hyperparameters   \n",
      "l1_strength: -0.001\n",
      "l2_strength: 0.0\n",
      "lr         : 0.01\n",
      "file_name  : 10180408_8\n",
      "*********************************\n",
      "Epoch 01/50, Train acc 0.5000 loss 1.2223, Val acc 0.5000 loss 0.3419\n",
      "Epoch 02/50, Train acc 0.5080 loss 0.5530, Val acc 0.5000 loss 0.0639\n",
      "Epoch 03/50, Train acc 0.5320 loss 0.4280, Val acc 0.5000 loss 0.2209\n",
      "Epoch 04/50, Train acc 0.5520 loss 0.4135, Val acc 0.5150 loss 0.0493\n",
      "Epoch 05/50, Train acc 0.4920 loss 0.4777, Val acc 0.5200 loss 0.2308\n",
      "Epoch 06/50, Train acc 0.4900 loss 0.3906, Val acc 0.5140 loss 0.0510\n",
      "Epoch 07/50, Train acc 0.5400 loss 0.3018, Val acc 0.5190 loss 0.0674\n",
      "Epoch 08/50, Train acc 0.5200 loss 0.3707, Val acc 0.5190 loss 0.0787\n",
      "Epoch 09/50, Train acc 0.5400 loss 0.3788, Val acc 0.5360 loss 0.0293\n",
      "Epoch 10/50, Train acc 0.5360 loss 0.3258, Val acc 0.5060 loss 0.1314\n",
      "Epoch 11/50, Train acc 0.4880 loss 0.3885, Val acc 0.5500 loss 0.0239\n",
      "Epoch 12/50, Train acc 0.4960 loss 0.4541, Val acc 0.4810 loss 0.1108\n",
      "Epoch 13/50, Train acc 0.5340 loss 0.5070, Val acc 0.5000 loss 0.2333\n",
      "Epoch 14/50, Train acc 0.5220 loss 0.5572, Val acc 0.5240 loss 0.2715\n",
      "Epoch 15/50, Train acc 0.5260 loss 0.8448, Val acc 0.5260 loss 0.1534\n",
      "Epoch 16/50, Train acc 0.5380 loss 0.2735, Val acc 0.4970 loss 0.1870\n",
      "Epoch 17/50, Train acc 0.5320 loss 0.2687, Val acc 0.4990 loss 0.0924\n",
      "Epoch 18/50, Train acc 0.4800 loss 0.3319, Val acc 0.5250 loss 0.1193\n",
      "Epoch 19/50, Train acc 0.4840 loss 0.7042, Val acc 0.5070 loss 0.1448\n",
      "Epoch 20/50, Train acc 0.5080 loss 0.6356, Val acc 0.4820 loss 0.2841\n",
      "Epoch 21/50, Train acc 0.5260 loss 0.5305, Val acc 0.5000 loss 0.0851\n",
      "Epoch 22/50, Train acc 0.5400 loss 0.6181, Val acc 0.5010 loss 0.1853\n",
      "Epoch 23/50, Train acc 0.5080 loss 0.4488, Val acc 0.4830 loss 0.0901\n",
      "Epoch 24/50, Train acc 0.5000 loss 0.5755, Val acc 0.5540 loss 0.0645\n",
      "Epoch 25/50, Train acc 0.5340 loss 0.4273, Val acc 0.5000 loss 0.2838\n",
      "Epoch 26/50, Train acc 0.5240 loss 0.4353, Val acc 0.5400 loss 0.0446\n",
      "Epoch 27/50, Train acc 0.5120 loss 0.4803, Val acc 0.5060 loss 0.0746\n",
      "Epoch 28/50, Train acc 0.5020 loss 0.5833, Val acc 0.4830 loss 0.1463\n",
      "Epoch 29/50, Train acc 0.5220 loss 0.6087, Val acc 0.5190 loss 0.0834\n",
      "Epoch 30/50, Train acc 0.5440 loss 0.2464, Val acc 0.5700 loss 0.0264\n",
      "Epoch 31/50, Train acc 0.5560 loss 0.2973, Val acc 0.4840 loss 0.2384\n",
      "Epoch 32/50, Train acc 0.5220 loss 1.2128, Val acc 0.5000 loss 0.3207\n",
      "Epoch 33/50, Train acc 0.5320 loss 0.8661, Val acc 0.4890 loss 0.0736\n",
      "Epoch 34/50, Train acc 0.5700 loss 0.1637, Val acc 0.5220 loss 0.0479\n",
      "Epoch 35/50, Train acc 0.5000 loss 0.3341, Val acc 0.5230 loss 0.0388\n",
      "Epoch 36/50, Train acc 0.5240 loss 0.1827, Val acc 0.5260 loss 0.0412\n",
      "Epoch 37/50, Train acc 0.5820 loss 0.1151, Val acc 0.5070 loss 0.0715\n",
      "Epoch 38/50, Train acc 0.5440 loss 0.5312, Val acc 0.5060 loss 0.1096\n",
      "Epoch 39/50, Train acc 0.5320 loss 0.7496, Val acc 0.5030 loss 0.2720\n",
      "Epoch 40/50, Train acc 0.5080 loss 0.5457, Val acc 0.5560 loss 0.0417\n",
      "Epoch 41/50, Train acc 0.5000 loss 0.7479, Val acc 0.5240 loss 0.0825\n",
      "Epoch 42/50, Train acc 0.5540 loss 0.6821, Val acc 0.5210 loss 0.2955\n",
      "Epoch 43/50, Train acc 0.4960 loss 0.5409, Val acc 0.4830 loss 0.1120\n",
      "Epoch 44/50, Train acc 0.5060 loss 0.5072, Val acc 0.5100 loss 0.0849\n",
      "Epoch 45/50, Train acc 0.5400 loss 0.6953, Val acc 0.5070 loss 0.0933\n",
      "Epoch 46/50, Train acc 0.5000 loss 1.1943, Val acc 0.4820 loss 0.2654\n",
      "Epoch 47/50, Train acc 0.5500 loss 0.4137, Val acc 0.5000 loss 0.1034\n",
      "Epoch 48/50, Train acc 0.4940 loss 0.5128, Val acc 0.5300 loss 0.0758\n",
      "Epoch 49/50, Train acc 0.5420 loss 0.3187, Val acc 0.5450 loss 0.0379\n",
      "Epoch 50/50, Train acc 0.5120 loss 0.3824, Val acc 0.4840 loss 0.2141\n"
     ]
    }
   ],
   "source": [
    "def log_info(info):\n",
    "    max_len = max(len(arg_name) for arg_name in info)\n",
    "    line = '*' * (max_len + 2 + 20)\n",
    "\n",
    "    print(line)\n",
    "\n",
    "    print(\"Arguments & Hyperparameters\".center(max_len + 2 + 20))\n",
    "\n",
    "    for arg_name, arg_value in info.items():\n",
    "        print(f\"{arg_name.ljust(max_len)}: {arg_value}\")\n",
    "\n",
    "    print(line)\n",
    "\n",
    "log_info(info)\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    logs = [f\"Epoch {i + 1:02}/{50}\", ]\n",
    "    tr_acc, tr_loss = run_epoch(train_loader, network, loss_fn, optimizer, True, device)\n",
    "    val_acc, val_loss = run_epoch(val_loader, network, loss_fn, optimizer, False, device)\n",
    "    tr_log = f\"Train acc {tr_acc:.4f} loss {tr_loss:.4f}\"\n",
    "    val_log = f\"Val acc {val_acc:.4f} loss {val_loss:.4f}\"\n",
    "    logs.append(tr_log)\n",
    "    logs.append(val_log)\n",
    "    print(\", \".join(logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
