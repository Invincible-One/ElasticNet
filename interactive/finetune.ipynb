{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetune the saved models to see whether they forgot things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "from models import get_model, model_config\n",
    "from data import data_config\n",
    "from data.datasets import TwilightDuo\n",
    "from main import get_device\n",
    "\n",
    "class ProtendArgs:\n",
    "    #model = \"FullyConnectedNetwork\"\n",
    "    model = \"VGG_like\"\n",
    "    dataset = \"TwilightDuo\"\n",
    "    #model_config = [2048, 512]\n",
    "    model_config = [32, 'M', 64, 'M', 128, 'M', 256, 'M', 512, 'M', 1024, 'M', 1024, 'M', 1024]\n",
    "\n",
    "\n",
    "def load_model(args, fname):\n",
    "    base_folder = \"/scratch/ym2380/saved_models\"\n",
    "    fname = f\"{fname}.pth\"\n",
    "    fpath = os.path.join(base_folder, args.model, args.dataset, fname)\n",
    "    \n",
    "    model = get_model(args)\n",
    "    model.load_state_dict(torch.load(fpath))\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    return model\n",
    "\n",
    "def run_epoch(\n",
    "    dataloader,\n",
    "    model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    train,\n",
    "    device,\n",
    "    ):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        network.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = len(dataloader.dataset)\n",
    "    \n",
    "    with torch.set_grad_enabled(train):\n",
    "        for batch_idx, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            if model_config[args.model][\"input_type\"] == \"flattened\":\n",
    "                X = X.view(X.size(0), -1)\n",
    "            \n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(X)\n",
    "            loss_v = loss_fn(outputs, y)\n",
    "            total_loss += loss_v.item()\n",
    "            \n",
    "            if train:\n",
    "                loss_v.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions =  (predicted == y).sum().item()\n",
    "            correct += correct_predictions\n",
    "    \n",
    "    return correct / total, total_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add fname\n",
    "fname = \"10181152_9\"\n",
    "info = {\n",
    "    \"l1_strength\": 0.01,\n",
    "    \"l2_strength\": 0.005,\n",
    "    \"lr\": 0.001,\n",
    "}\n",
    "info[\"file_name\"] = fname\n",
    "\n",
    "args = ProtendArgs()\n",
    "device = get_device()\n",
    "\n",
    "\n",
    "train_data = TwilightDuo(n_samples=500, bias=0, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=25, num_workers=1, pin_memory=True)\n",
    "val_data = TwilightDuo(n_samples=1000, bias=0, transform=transforms.ToTensor())\n",
    "val_loader = DataLoader(val_data, shuffle=False, batch_size=100, num_workers=1, pin_memory=True)\n",
    "\n",
    "network = load_model(args, fname=fname).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#try different lrs\n",
    "optimizer = optim.Adam(network.classifier.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************\n",
      "   Arguments & Hyperparameters   \n",
      "l1_strength: 0.01\n",
      "l2_strength: 0.005\n",
      "lr         : 0.001\n",
      "file_name  : 10181152_9\n",
      "*********************************\n",
      "Epoch 01/50, Train acc 0.6860 loss 0.0459, Val acc 0.7750 loss 0.0049\n",
      "Epoch 02/50, Train acc 0.8300 loss 0.0159, Val acc 0.9340 loss 0.0020\n",
      "Epoch 03/50, Train acc 0.9000 loss 0.0094, Val acc 0.9860 loss 0.0013\n",
      "Epoch 04/50, Train acc 0.8360 loss 0.0132, Val acc 0.9390 loss 0.0017\n",
      "Epoch 05/50, Train acc 0.9120 loss 0.0081, Val acc 0.9820 loss 0.0010\n",
      "Epoch 06/50, Train acc 0.8740 loss 0.0121, Val acc 0.9910 loss 0.0007\n",
      "Epoch 07/50, Train acc 0.9280 loss 0.0070, Val acc 0.7900 loss 0.0051\n",
      "Epoch 08/50, Train acc 0.9020 loss 0.0088, Val acc 0.9310 loss 0.0018\n",
      "Epoch 09/50, Train acc 0.9340 loss 0.0067, Val acc 0.9470 loss 0.0013\n",
      "Epoch 10/50, Train acc 0.9440 loss 0.0052, Val acc 0.9860 loss 0.0007\n",
      "Epoch 11/50, Train acc 0.9940 loss 0.0015, Val acc 0.9980 loss 0.0002\n",
      "Epoch 12/50, Train acc 0.9940 loss 0.0017, Val acc 0.9650 loss 0.0007\n",
      "Epoch 13/50, Train acc 0.9740 loss 0.0037, Val acc 0.9970 loss 0.0002\n",
      "Epoch 14/50, Train acc 0.9940 loss 0.0015, Val acc 0.9990 loss 0.0002\n",
      "Epoch 15/50, Train acc 0.9920 loss 0.0015, Val acc 0.9980 loss 0.0002\n",
      "Epoch 16/50, Train acc 0.9900 loss 0.0018, Val acc 0.9970 loss 0.0002\n",
      "Epoch 17/50, Train acc 0.9520 loss 0.0045, Val acc 0.9850 loss 0.0005\n",
      "Epoch 18/50, Train acc 0.9660 loss 0.0039, Val acc 0.9480 loss 0.0015\n",
      "Epoch 19/50, Train acc 0.9560 loss 0.0040, Val acc 0.9980 loss 0.0001\n",
      "Epoch 20/50, Train acc 0.9760 loss 0.0030, Val acc 0.9970 loss 0.0003\n",
      "Epoch 21/50, Train acc 0.9800 loss 0.0023, Val acc 0.9930 loss 0.0002\n",
      "Epoch 22/50, Train acc 0.9860 loss 0.0016, Val acc 0.9990 loss 0.0001\n",
      "Epoch 23/50, Train acc 0.9800 loss 0.0021, Val acc 0.9970 loss 0.0001\n",
      "Epoch 24/50, Train acc 0.9520 loss 0.0040, Val acc 1.0000 loss 0.0001\n",
      "Epoch 25/50, Train acc 0.9160 loss 0.0089, Val acc 1.0000 loss 0.0001\n",
      "Epoch 26/50, Train acc 0.9920 loss 0.0017, Val acc 1.0000 loss 0.0001\n",
      "Epoch 27/50, Train acc 0.9960 loss 0.0009, Val acc 0.9970 loss 0.0001\n",
      "Epoch 28/50, Train acc 0.9920 loss 0.0012, Val acc 0.9970 loss 0.0001\n",
      "Epoch 29/50, Train acc 0.9340 loss 0.0070, Val acc 0.9350 loss 0.0015\n",
      "Epoch 30/50, Train acc 0.9800 loss 0.0025, Val acc 0.9690 loss 0.0008\n",
      "Epoch 31/50, Train acc 0.9880 loss 0.0017, Val acc 0.9580 loss 0.0010\n",
      "Epoch 32/50, Train acc 0.9680 loss 0.0034, Val acc 0.9560 loss 0.0011\n",
      "Epoch 33/50, Train acc 0.9300 loss 0.0063, Val acc 0.9850 loss 0.0004\n",
      "Epoch 34/50, Train acc 0.9740 loss 0.0024, Val acc 0.9540 loss 0.0011\n",
      "Epoch 35/50, Train acc 0.9260 loss 0.0123, Val acc 1.0000 loss 0.0001\n",
      "Epoch 36/50, Train acc 0.9720 loss 0.0029, Val acc 0.9730 loss 0.0008\n",
      "Epoch 37/50, Train acc 0.9580 loss 0.0038, Val acc 0.9990 loss 0.0000\n",
      "Epoch 38/50, Train acc 0.9780 loss 0.0020, Val acc 0.9980 loss 0.0001\n",
      "Epoch 39/50, Train acc 1.0000 loss 0.0003, Val acc 0.9980 loss 0.0001\n",
      "Epoch 40/50, Train acc 0.9900 loss 0.0014, Val acc 0.9940 loss 0.0002\n",
      "Epoch 41/50, Train acc 0.9920 loss 0.0009, Val acc 0.9900 loss 0.0003\n",
      "Epoch 42/50, Train acc 0.9940 loss 0.0005, Val acc 0.9980 loss 0.0001\n",
      "Epoch 43/50, Train acc 0.9960 loss 0.0006, Val acc 0.9980 loss 0.0000\n",
      "Epoch 44/50, Train acc 1.0000 loss 0.0002, Val acc 0.9980 loss 0.0001\n",
      "Epoch 45/50, Train acc 0.9980 loss 0.0002, Val acc 1.0000 loss 0.0000\n",
      "Epoch 46/50, Train acc 0.9760 loss 0.0029, Val acc 0.9780 loss 0.0006\n",
      "Epoch 47/50, Train acc 0.9880 loss 0.0013, Val acc 0.9980 loss 0.0001\n",
      "Epoch 48/50, Train acc 0.9980 loss 0.0003, Val acc 0.9990 loss 0.0000\n",
      "Epoch 49/50, Train acc 1.0000 loss 0.0002, Val acc 0.9980 loss 0.0001\n",
      "Epoch 50/50, Train acc 0.9900 loss 0.0012, Val acc 0.9990 loss 0.0000\n"
     ]
    }
   ],
   "source": [
    "def log_info(info):\n",
    "    max_len = max(len(arg_name) for arg_name in info)\n",
    "    line = '*' * (max_len + 2 + 20)\n",
    "\n",
    "    print(line)\n",
    "\n",
    "    print(\"Arguments & Hyperparameters\".center(max_len + 2 + 20))\n",
    "\n",
    "    for arg_name, arg_value in info.items():\n",
    "        print(f\"{arg_name.ljust(max_len)}: {arg_value}\")\n",
    "\n",
    "    print(line)\n",
    "\n",
    "log_info(info)\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    logs = [f\"Epoch {i + 1:02}/{50}\", ]\n",
    "    tr_acc, tr_loss = run_epoch(train_loader, network, loss_fn, optimizer, True, device)\n",
    "    val_acc, val_loss = run_epoch(val_loader, network, loss_fn, optimizer, False, device)\n",
    "    tr_log = f\"Train acc {tr_acc:.4f} loss {tr_loss:.4f}\"\n",
    "    val_log = f\"Val acc {val_acc:.4f} loss {val_loss:.4f}\"\n",
    "    logs.append(tr_log)\n",
    "    logs.append(val_log)\n",
    "    print(\", \".join(logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
